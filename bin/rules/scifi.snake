""" Snakerules for counting scifi-RNA-seq data """

rule preprocess: # split input fastq files from RAW_DATA by well and format for alevin-fry
    input:
        data = RAW_DATA,
        allowlist = RAW_DATA + "/allowlist.tsv"
    output:
        expand("{out_data}/preprocessed_fastqs/{sample}_{read}.fastq.gz",
               sample = SAMPLES,
               out_data = OUT_DATA,
               read = ["R1", "R2", "I1"])
    params:
        job_name = "preprocess",
        memory = "select[mem>64] rusage[mem=64]"
    log:
      "logs/preprocess.out"
    shell:
        """
        {SRC}/preprocessing.py \
        {input.data} \
        {input.allowlist}
        """

rule make_txome: # make a splici (spliced + intron) transcriptome for alevin-fry
    input:
        genome = FASTA,
        gtf = GTF
    output:
        "{out_data}/ref/transcriptome/transcriptome_splici_fl86.fa",
        "{out_data}/ref/transcriptome/transcriptome_splici_fl86_t2g.tsv",
        "{out_data}/ref/transcriptome/transcriptome_splici_fl86_t2g_3col.tsv"
    params:
        job_name = "make_txome",
        memory = "select[mem>64] rusage[mem=64]",
        read_length = 91,
        flank_trim_length = 5,
        out_dir = "{out_data}/ref/transcriptome"
    log:
        "logs/make_txome.out"
    shell:
        """
        {SRC}/make_splici_txome.R \
        {input.gtf} \
        {input.genome} \
        {params.read_length} \
        {params.flank_trim_length} \
        {params.out_dir}
        """

rule build_idx: # build a splici (spliced + intron) index for alevin-fry
    input:
        fasta = "{out_data}/ref/transcriptome/transcriptome_splici_fl86.fa"
    output:
        "{out_data}/ref/idx/complete_ref_lens.bin",
        "{out_data}/ref/idx/ctable.bin",
        "{out_data}/ref/idx/ctg_offsets.bin",
        "{out_data}/ref/idx/duplicate_clusters.tsv",
        "{out_data}/ref/idx/info.json",
        "{out_data}/ref/idx/mphf.bin",
        "{out_data}/ref/idx/pos.bin",
        "{out_data}/ref/idx/pre_indexing.bin",
        "{out_data}/ref/idx/rank.bin",
        "{out_data}/ref/idx/refAccumLengths.bin",
        "{out_data}/ref/idx/ref_indexing.bin",
        "{out_data}/ref/idx/reflengths.bin",
        "{out_data}/ref/idx/refseq.bin",
        "{out_data}/ref/idx/seq.bin",
        "{out_data}/ref/idx/versionInfo.json"
    params:
        job_name = "build_idx",
        memory = "select[mem>64] rusage[mem=64]",
        out_dir = "{out_data}/ref/idx"
    log:
        "logs/build_idx.out"
    threads:
        16
    shell:
        """
        salmon index \
            -t {input.fasta} \
            -i {params.out_dir} \
            -p {threads}
        """

rule map_reads: # map reads and generate a RAD (Reduced Alignment Data) file
    input:
        R1 = "{out_data}/preprocessed_fastqs/{sample}_R1.fastq.gz",
        R2 = "{out_data}/preprocessed_fastqs/{sample}_R2.fastq.gz",
        idx = rules.build_idx.output,
        tgmap = "{out_data}/ref/transcriptome/transcriptome_splici_fl86_t2g.tsv"
    output:
        "{out_data}/{sample}/map/alevin/alevin.log",
        "{out_data}/{sample}/map/aux_info/meta_info.json",
        "{out_data}/{sample}/map/cmd_info.json",
        "{out_data}/{sample}/map/libParams",
        "{out_data}/{sample}/map/logs/salmon_quant.log",
        "{out_data}/{sample}/map/map.rad",
        "{out_data}/{sample}/map/unmapped_bc_count.bin",
    params:
        job_name = "map_reads",
        memory = "select[mem>64] rusage[mem=64]",
        library_type = "ISR",
        end = 5,
        barcodeLength = 16,
        umiLength = 8,
        out_dir = "{out_data}/{sample}/map"
    log:
        "logs/map_reads/{sample}.out"
    threads:
        16
    shell:
        """
        salmon alevin \
            -l {params.library_type} \
            -1 {input.R1} \
            -2 {input.R2} \
            -i {input.idx} \
            -p {threads} \
            -o {params.out_dir} \
            --tgmap {input.tgmap} \
            --end {params.end} \
            --barcodeLength {params.barcodeLength} \
            --umiLength {params.umiLength} \
            --keepCBFraction 1 \
            --sketch
        """

rule generate_permit_list: # generate a "permit list" of barcodes believed to belong to real (high-quality) cells
    input:
        mapped_reads = rules.map_reads.output
    output:
        "{out_data}/{sample}/quant/all_freq.tsv",
        "{out_data}/{sample}/quant/collate.json",
        "{out_data}/{sample}/quant/generate_permit_list.json",
        "{out_data}/{sample}/quant/map.collated.rad",
        "{out_data}/{sample}/quant/permit_freq.tsv",
        "{out_data}/{sample}/quant/permit_map.bin",
        "{out_data}/{sample}/quant/unmapped_bc_count_collated.bin"
    params:
        job_name = "generate_permit_list",
        memory = "select[mem>64] rusage[mem=64]",
        out_dir = "{out_data}/{sample}/quant"
    log:
        "logs/generate_permit_list/{sample}.out"
    shell:
        """
        conda activate alevin_fry
        alevin-fry generate-permit-list \
            -d fw \
            --force-cells 100000 \
            -i {input.mapped_reads} \
            -o {params.out_dir}
        """

rule collate: # collate the input RAD file
    input:
        quant = rules.generate_permit_list.output,
        rad_dir = rules.map_reads.output
    params:
        job_name = "collate",
        memory = "select[mem>64] rusage[mem=64]"
    log:
        "logs/collate/{sample}.out"
    threads:
        16
    shell:
        """
        conda activate alevin_fry
        alevin-fry collate \
            -t {threads} \
            -i {input.quant} \
            -r {input.rad_dir}
        """

rule quant: # generate a cell-by-gene count matrix from the collated mapping file
    input:
        quant = rules.generate_permit_list.output,
        tgmap = "{out_data}/ref/transcriptome/transcriptome_splici_fl86_t2g.tsv"
    output:
        "{out_data}/{sample}/quant_res/alevin/quants_mat_cols.txt",
        "{out_data}/{sample}/quant_res/alevin/quants_mat.mtx",
        "{out_data}/{sample}/quant_res/alevin/quants_mat_rows.txt",
        "{out_data}/{sample}/quant_res/featureDump.txt",
        "{out_data}/{sample}/quant_res/quant.json"
    params:
        job_name = "quant",
        memory = "select[mem>64] rusage[mem=64]",
        out_dir = "{out_data}/{sample}/quant_res"
    log:
        "logs/quant/{sample}.out"
    threads:
        16
    shell:
        """
        conda activate alevin_fry
        alevin-fry quant \
            -t {threads} \
            -i {input.quant} \
            -o {params.out_dir} \
            --tg-map {input.tgmap} \
            --resolution cr-like \
            --use-mtx
        """